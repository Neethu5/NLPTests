{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging with Pre-Trained Sequence Tagging Models\n",
    "\n",
    "Let's use a pre-trained model for named entity recognition (NER). This model was trained over the English CoNLL-03 task and can recognize 4 different entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "2019-03-21 15:32:53,538 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/NER-conll03-english/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmp21qyoa0b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432197603/432197603 [00:18<00:00, 23356545.83B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:33:12,386 copying /tmp/tmp21qyoa0b to cache at /home/quick/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:33:12,592 removing temp file /tmp/tmp21qyoa0b\n",
      "2019-03-21 15:33:12,593 loading file /home/quick/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington .')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-span [1,2]: \"George Washington\"\n",
      "LOC-span [5]: \"Washington\"\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which indicates that \"George Washington\" is a person (PER) and \"Washington\" is a location (LOC). Each such Span has a text, a tag value, its position in the sentence and \"score\" that indicates how confident the tagger is that the prediction is correct. You can also get additional information, such as the position offsets of each entity in the sentence by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'confidence': 0.9967881441116333,\n",
      "               'end_pos': 17,\n",
      "               'start_pos': 0,\n",
      "               'text': 'George Washington',\n",
      "               'type': 'PER'},\n",
      "              {'confidence': 0.9993712306022644,\n",
      "               'end_pos': 36,\n",
      "               'start_pos': 26,\n",
      "               'text': 'Washington',\n",
      "               'type': 'LOC'}],\n",
      " 'labels': [],\n",
      " 'text': 'George Washington went to Washington .'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Pre-Trained Sequence Tagger Models\n",
    "\n",
    "You choose which pre-trained model you load by passing the appropriate\n",
    "string to the `load()` method of the `SequenceTagger` class. Currently, the following pre-trained models\n",
    "are provided:\n",
    "\n",
    "#### English Models\n",
    "\n",
    "| ID | Task | Training Dataset | Accuracy |\n",
    "| -------------    | ------------- |------------- |------------- |\n",
    "| 'ner' | 4-class Named Entity Recognition |  Conll-03  |  **93.24** (F1) |\n",
    "| 'ner-ontonotes' | 12-class Named Entity Recognition |  Ontonotes  |  **89.52** (F1) |\n",
    "| 'chunk' |  Syntactic Chunking   |  Conll-2000     |  **96.61** (F1) |\n",
    "| 'pos' |  Part-of-Speech Tagging |  Ontonotes     |  **98.01** (Accuracy) |\n",
    "| 'frame'  |   Semantic Frame Detection  (***Experimental***)|  Propbank 3.0     |  **93.92** (F1) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging a List of Sentences\n",
    "\n",
    "\n",
    "Often, you may want to tag an entire text corpus. In this case, you need to split the corpus into sentences and pass a list of Sentence objects to the .predict() method.\n",
    "\n",
    "For instance, you can use the sentence splitter of segtok to split your text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:39:26,035 loading file /home/quick/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"This is a sentence .\" - 5 Tokens,\n",
       " Sentence: \"This is another sentence .\" - 5 Tokens,\n",
       " Sentence: \"I love Berlin .\" - 4 Tokens,\n",
       " Sentence: \"George Washington went to Washington .\" - 6 Tokens]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your text of many sentences\n",
    "text = \"This is a sentence. This is another sentence. I love Berlin. George Washington went to Washington .\"\n",
    "\n",
    "# use a library to split into sentences\n",
    "from segtok.segmenter import split_single\n",
    "sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "\n",
    "# predict tags for list of sentences\n",
    "tagger: SequenceTagger = SequenceTagger.load('ner')\n",
    "tagger.predict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence .\n",
      "This is another sentence .\n",
      "I love Berlin <S-LOC> .\n",
      "\t LOC-span [3]: \"Berlin\"\n",
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n",
      "\t PER-span [1,2]: \"George Washington\"\n",
      "\t LOC-span [5]: \"Washington\"\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence.to_tagged_string())\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print(\"\\t\",entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging with Pre-Trained Text Classification Models\n",
    "\n",
    "\n",
    "Let's use a pre-trained model for detecting positive or negative comments. This model was trained over the IMDB dataset and can recognize positive and negative sentiment in English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:41:19,848 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/TEXT-CLASSIFICATION_imdb/imdb.pt not found in cache, downloading to /tmp/tmpt6vul3wr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794252905/2794252905 [02:05<00:00, 22265517.33B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:43:25,708 copying /tmp/tmpt6vul3wr to cache at /home/quick/.flair/models/imdb.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-21 15:43:27,025 removing temp file /tmp/tmpt6vul3wr\n",
      "2019-03-21 15:43:27,025 loading file /home/quick/.flair/models/imdb.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quick/anaconda3/lib/python3.7/site-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEGATIVE (1.0)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "sentence = Sentence('This film hurts. It is so bad that I am confused.')\n",
    "\n",
    "# predict NER tags\n",
    "classifier.predict(sentence)\n",
    "\n",
    "# print sentence with predicted labels\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Pre-Trained Text Classification Models\n",
    "\n",
    "You choose which pre-trained model you load by passing the appropriate\n",
    "string to the `load()` method of the `TextClassifier` class. Currently, the following pre-trained models\n",
    "are provided:\n",
    "\n",
    "| ID | Language | Task | Training Dataset | Accuracy |\n",
    "| ------------- | ---- | ------------- |------------- |------------- |\n",
    "| 'en-sentiment' | English | detecting positive and negative sentiment | movie reviews from [IMDB](http://ai.stanford.edu/~amaas/data/sentiment/)  |  **90.54** (Micro F1) |\n",
    "| 'de-offensive-language' | German | detecting offensive language | [GermEval 2018 Task 1](https://projects.fzai.h-da.de/iggsa/projekt/) |  **75.71** (Macro F1) |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
